{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c5f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mahotas\n",
    "#pip install pycountry\n",
    "#pip install countryinfo\n",
    "#pip install pingouin\n",
    "#pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c608e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import mahotas as mt\n",
    "import glob\n",
    "import os\n",
    "import PIL\n",
    "from PIL import ImageOps\n",
    "import numpy as np\n",
    "import pycountry\n",
    "from countryinfo import CountryInfo\n",
    "import pingouin as pg\n",
    "from IPython.display import Image, display\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import pingouin as pg\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c834f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8976dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob('/Users/james/Downloads/world_flags/*.png')  # list of all .png files in the directory\n",
    "\n",
    "names = []\n",
    "images = []\n",
    "\n",
    "for i in filenames:\n",
    "    names.append(os.path.basename(i)[:-4])\n",
    "    img = Image.open(i)\n",
    "    img = img.convert(\"RGBA\")\n",
    "    img = ImageOps.grayscale(img)\n",
    "    img = np.asanyarray(img)\n",
    "    images.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b87e2ab",
   "metadata": {},
   "source": [
    "# What are haralick features?\n",
    "\n",
    "Haralick features are a set of texture descriptors derived from the Gray Level Co-occurrence Matrix (GLCM), which is a method of examining the texture of an image by considering the spatial relationship of pixels. The GLCM is a matrix that represents how often different combinations of pixel brightness values (gray levels) occur in an image. From the GLCM, various statistical measures (Haralick features) can be calculated to describe the texture of the image. There are 14 commonly used Haralick features, each capturing different aspects of texture:\n",
    "\n",
    "1. Angular Second Moment (ASM): Measures image homogeneity. Higher values indicate more homogeneity or uniformity in the image texture.\n",
    "\n",
    "2. Contrast: Measures the local variations in the gray-level co-occurrence matrix. Higher contrast values indicate greater disparities in pixel intensities.\n",
    "\n",
    "3. Correlation: Evaluates the joint probability occurrence of the specified pixel pairs. High correlation indicates a predictable relationship between pixel values.\n",
    "\n",
    "4. Sum of Squares: Variance: Reflects the variance of the image intensities. It's a measure of the spread or dispersion of pixel values.\n",
    "\n",
    "5. Inverse Difference Moment (IDM): Also known as Homogeneity. It's high when the image has less contrast, indicating more homogeneity.\n",
    "\n",
    "6. Sum Average: The average value of the sum of gray levels of pixel pairs. It's a measure of the overall brightness.\n",
    "\n",
    "7. Sum Variance: Measures the variance of the sum of the GLCM. It assesses the variance in the sum average.\n",
    "\n",
    "8. Sum Entropy: Measures the randomness or complexity in the sum of gray levels. Higher values indicate more complexity.\n",
    "\n",
    "9. Entropy: Quantifies the disorder or complexity of the image. Higher entropy values imply more complex texture patterns.\n",
    "\n",
    "10. Difference Variance: Measures the variance in the difference between the gray levels of the pixel pairs.\n",
    "\n",
    "11. Difference Entropy: Measures the complexity or randomness of the differences between the gray levels of the pixel pairs.\n",
    "\n",
    "12. Information Measures of Correlation I & II: These two features provide information about the complexity of the image texture as seen in the GLCM. They measure how correlated a pixel is to its neighbor over the whole image.\n",
    "\n",
    "13. Maximal Correlation Coefficient (MCC): This measures the correlation between the probabilities of the pixel pairs. It requires eigenvalue calculations and is often more computationally intensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe54231",
   "metadata": {},
   "source": [
    "# Compute haralick features and create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "448ab9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "haralick = [mt.features.haralick(i, return_mean = True, compute_14th_feature=True) for i in images]\n",
    "\n",
    "\n",
    "features = ['angular_2nd_momentum', 'contrast', 'correlation', 'SS_variance', \\\n",
    "            'Inverse_diff_moment', 'sum_average', 'sum_variance', 'sum_entropy', \\\n",
    "            'entropy','difference_variation', 'difference_entropy', 'info_corr_1', \\\n",
    "            'info_corr_2', 'max_corr_coeff']\n",
    "\n",
    "h_df = pd.DataFrame(haralick, columns = features)\n",
    "h_df['short_names'] = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c96f5fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345f6ad0",
   "metadata": {},
   "source": [
    "# Get full country names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1f067572",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_name = []\n",
    "\n",
    "for i in h_df['short_names']:\n",
    "    try:\n",
    "        full_name.append(pycountry.countries.get(alpha_2=i).name)\n",
    "    except:\n",
    "        full_name.append(np.nan)\n",
    "        \n",
    "h_df['full_name'] = full_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633849e4",
   "metadata": {},
   "source": [
    "# Get number of borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "05ed0eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "borders = []\n",
    "\n",
    "\n",
    "for i in h_df['full_name']:\n",
    "    try:\n",
    "        a = CountryInfo(i)\n",
    "        borders.append(len(a.borders()))\n",
    "    except:\n",
    "        borders.append(np.nan)\n",
    "\n",
    "h_df['borders'] = borders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b6e20",
   "metadata": {},
   "source": [
    "## Get data on ethnic diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a4baf236",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnic = pd.read_csv('/Users/james/Downloads/ethnic_fractions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b2a1f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_df = pd.merge(h_df, ethnic, on='full_name', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472307f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = 'ethnic fractionalization', y = 'entropy', data = h_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c722aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = pg.linear_regression(h_df['ethnic fractionalization'], h_df['entropy'], remove_na = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d8627894",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h_df[['ethnic fractionalization', 'borders', 'entropy', 'contrast', 'full_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d05dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_e = (data['entropy'].min() + data['entropy'].max()) / 2\n",
    "mid_c = (data['contrast'].min() + data['contrast'].max()) / 2\n",
    "\n",
    "data['entropy'] = data['entropy'] - mid_e\n",
    "data['contrast'] = data['contrast'] - mid_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57af46b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data, x=\"entropy\", y=\"contrast\", hover_data = ['full_name', 'borders'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7075b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
